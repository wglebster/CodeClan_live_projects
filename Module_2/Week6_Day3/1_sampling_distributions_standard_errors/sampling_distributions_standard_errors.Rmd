---
title: "Sampling distributions"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

# Learning objectives

* Understand the concepts of:
  - sampling distribution 
  - standard error
* Broadly understand why the central limit theorem is important


**Duration - 90 minutes**<br>

<hr>

# Sampling distributions: means

Earlier we mentioned the terms *population* and *sample*, the related concepts of *population parameter* and *sample statistic*, and understood that a statistic is an estimate of a population parameter calculated from a sample.

<div class='emphasis'>
**Population**: **all** the objects, elements or entities conceivably of interest for a investigative study. We will very rarely have access to data for an entire population.

**Parameters**: properties of the **population**, such as the mean or standard deviation.

**Sample**: a part or subset of the population chosen for the purpose of the study. We sample because it is often impractical or impossible to gather data for entire populations.

**Statistics**: properties of a **sample**, such as the mean or standard deviation.
</div>

<br>

We're going to look in more detail at the concept of a sampling distribution, i.e. the distribution built up by repeated sampling of a population, calculating some statistic of interest for each sample. 

We're going to use a dataset on customer churn in the telecomms sector. It's pretty rich in variables and contains many observations: this will help us to justify treating this data as a population from which we'll draw smaller samples.

<br>
<div class='emphasis'>
**Important note**

We're going to take a data set and **sample** it - i.e. keep a random small fraction of it and throw away the rest. We're doing this purely for teaching purposes: in real life data analysis, **you wouldn't do this**! You would use **all available data**, as this maximises the accuracy of any subsequent analysis. Keep this in mind throughout this and the next few lessons.
</div>
<br>

Let's load and explore the data:

```{r, message = FALSE}
library(tidyverse)
library(janitor)
```

```{r}
telco <- read_csv("data/telecomms_churn.csv")
telco <- clean_names(telco)
glimpse(telco)
```

Now, let's get the population parameters for

* the mean of `monthly_charges`
* the mean `tenure`
* the proportion of contracts that `churn`

Again, we will be treating the full dataset as if it were our 'population'

```{r}
summary_popn <- telco %>%
  summarise(
    mean_monthly_charges = mean(monthly_charges), 
    mean_tenure = mean(tenure),
    prop_churn = mean(churn == "Yes")
  ) 
summary_popn
```

Let's focus on a few variables of interest. We'll visualise the distributions of `monthly_charges` and `tenure`, and the counts of both levels of `churn`

```{r}
telco %>%
  ggplot(aes(x = monthly_charges)) + 
  geom_histogram(col = "white", fill = "steel blue", alpha = 0.7)

telco %>%
  ggplot(aes(x = tenure)) + 
  geom_histogram(col = "white", fill = "steel blue", alpha = 0.7)

telco %>%
  ggplot(aes(x = churn)) + 
  geom_bar(fill = "steel blue", alpha = 0.7)
```

We see that `monthly_charges` is bimodal (we have a broad range of charges from approximately €$40$ up to €$115$ and a narrow peak of charges below €$25$). 

Meanwhile `tenure` is not even near normal: it dips downward in the centre of the distribution, indicating that short and long tenures of contract are more probable than intermediate values.

We also see the `churn` proportion is imbalanced: "No" predominates over "Yes" in the dataset.

Now we'll start sampling!  Note that this example is **fictional**. If we had the required details of all the customers in the telecomms sector (i.e. we had knowledge of the complete population), then we wouldn’t need to sample and do statistics! Statistics is a means to let us go 'backward' here: it's saying *'we don't have knowledge of the full population and likely never will, but how reliably can we infer the properties of the population from a much smaller sample?'*

Let's take a random sample of $200$ from the 'population'. We are going to use the **simple random sampling** method (but there are other methods which we will touch on in the next lesson). 

<div class='emphasis'>
**Simple random sampling (SRS)** - a sampling method in which **every** element of the population has **an equal** probability of being selected into the sample.
</div>
<br>

We'll use the `rep_sample_n()` function from the `infer` package to do this.

```{r}
library(infer)
sample_200 <- telco %>%
  rep_sample_n(size = 200, reps = 1)
sample_200
```

We have $200$ random rows sampled from `telco`. Note that the sampling function adds a `replicate` column, and this just contains value `1` to indicate that all of these rows belong to the same 'replicate': more on this shortly. The function also `groups` by the `replicate` variable. To see this, use the `dplyr` `groups()` function!

```{r}
groups(sample_200)
```

Let's summarise this sample focusing on our three variables of interest.

```{r}
summary_sample_200 <- sample_200 %>%
  ungroup() %>%
  summarise(
    mean_monthly_charges = mean(monthly_charges), 
    mean_tenure = mean(tenure),
    prop_churn = mean(churn == "Yes")
  ) 
summary_sample_200
```

<br>
<div class='emphasis'>
**'Statistic' and 'Point Estimate' mean the same thing!**

We also call the **statistics** obtained from the sample **point estimates** of the population parameters: 'point estimate' because they are just one estimate calculated from a single sample. 
</div>
<br>

Given this sample and these point estimates, let's get the **sampling errors** for `mean_monthly_charges`, `mean_tenure` and `prop_churn` (these are just the differences between the point estimates and the population parameters)

<br>
<div class='emphasis'>
**Sampling error = point estimate - population parameter**

The **sampling error** is just the difference between the point estimate and population parameter. Often we won't be able to state sampling errors, as we rarely have access to data for whole populations (and therefore do not know the population parameter). 
</div>
<br>

```{r}
summary_sample_200 - summary_popn
```

<hr>

# Central limit theorem

Now what happens if we sample the population repeatedly?  

Let's take $5,000$ samples, each of size $200$, calculating values of the `mean_monthly_charges`, `mean_tenure` and `prop_churn` point estimates for each sample. In this way, we'll build up sampling distributions for each of these statistics. Remember that this is a fictional example: in reality it is highly unlikely we would have the time or money resources to be able to do $1,000$ samples!

<br>
<div class='emphasis'>
We call this process **resampling** in general.

Here we're in the somewhat 'fake' situation of already having a larger set of data ($7043$ observations in `telco`) from which we are randomly sampling $200$ observations. 

But, imagine we had just a single sample of $200$ observations from the data gathering phase of our analysis. It turns out that there would still be some benefit and insight to be gained from **resampling the sample observations with replacement**: we call this **bootstrapping**, it's one of the most interesting developments in modern statistics! We will discuss this further this afternoon. So, while we said it's highly unlikely we would be able to do $5,000$ resamples, lets imagine we can, because we will use bootstrapping to mimic this situation later today!
</div>
<br>

```{r}
rep_sample_200 <- telco %>%
  rep_sample_n(size = 200, reps = 5000) %>%
  summarise(
    mean_monthly_charges = mean(monthly_charges), 
    mean_tenure = mean(tenure),
    prop_churn = mean(churn == "Yes")
  ) 
rep_sample_200
```

Each of the `mean_monthly_charges`, `mean_tenure` and `prop_churn` columns contain statistics calculated from the sample labelled by `replicate`. These columns are the **sampling distributions** of the statistics.

<br>
<div class='emphasis'>
Be clear in your own mind what we did here:

* We drew $5,000$ random samples each of size $200$ observations from our `telco` population
* For **each sample (replicate)** we calculated the `mean(monthly_charges)`, `mean(tenure)` and `prop_churn`. These are our **statistics** (or **point estimates**).
* Each sample leads to slightly different point estimates: the collection of these $5,000$ estimates we call the **sampling distribution** of the statistic. 
* Finally we will take each sampling distribution and:
    - visualise it on a histogram
    - calculate the mean and standard deviation of the sampling distribution, this will tell us something about where the sampling distribution is **centred** and its **spread**.

</div>
<br>

Let's plot the sampling distributions, starting with `mean_monthly_charges`:

```{r}
# here ..density.. tells ggplot to use the probability density rather than count
# in the histogram
monthly_charges_plot <- rep_sample_200 %>%
  ggplot(aes(x = mean_monthly_charges)) + 
  geom_histogram(col = "white", fill = "steel blue", alpha = 0.7) +
  labs(x = "mean monthly_charges from each sample")
monthly_charges_plot
```

This looks normal! Remember though that the `monthly_charges` **wasn't normal**: it looked bimodal, so this is quite surprising at first sight!

<br>
<details>
<summary>**Checking normality**</summary>
Let's check normality more directly by overlaying a normal density curve with the parameters calculated from the `mean_monthly_charges` column of `rep_sample_200`. To do this, we need to plot the histogram of `mean_monthly_charges` as a probability density, rather than as a count (the default).

```{r}
rep_sample_200 %>%
  ggplot(aes(x = mean_monthly_charges)) + 
  geom_histogram(aes(y = ..density..), col = "white", fill = "steel blue", alpha = 0.7) +
  labs(x = "mean monthly_charges from each sample") +
  stat_function(
    fun = dnorm, 
    args = list(
      mean = mean(rep_sample_200$mean_monthly_charges), 
      sd = sd(rep_sample_200$mean_monthly_charges)
    ),
    col = "red"
  )
```
</details>
<br>

<br>
<blockquote class='task'>
**Task - 5 mins**  

Plot similar visualisations of the `mean_tenure` and `prop_churn` sampling distributions also held in `rep_sample_200`  

<details>
<summary>**Solution**</summary>

```{r}
tenure_plot <- rep_sample_200 %>%
  ggplot(aes(x = mean_tenure)) +
  geom_histogram(col = "white", fill = "steel blue", alpha = 0.7)
tenure_plot

churn_plot <- rep_sample_200 %>%
  ggplot(aes(x = prop_churn)) +
  geom_histogram(col = "white", fill = "steel blue", alpha = 0.7) 
churn_plot
```
</details>
</blockquote>
<br>

We have an interesting finding: even though the distributions of `monthly_charges`, `tenure` and even `churn` in the population were clearly not normal, their sampling distributions look normal! This is true of the vast majority of sampling distributions if sample sizes and number of resamples are large enough. 

This is a consequence of a really important statistical principle known as the **central limit theorem**. 

<br>
<div class='emphasis'>
**The central limit theorem**<br><br>

The central limit theorem says that the sampling distributions of means and proportions **tend to be normal** if we draw **a large enough number of sufficiently large samples**. Notionally, this is true regardless of the shape of the underlying distribution from which the statistics are calculated, but we'll see some conditions on this below.
</div>
<br>

<hr>

# What is a large enough sample? The 'n = 30' rule of thumb

This is just a very rough rule of thumb, but sampling distributions tend to be normal for samples of size $30$ and above. 

If the underlying distribution is symmetric and unimodal, we might be able to get away with smaller sample sizes, but if it is strongly skewed and/or bimodal and/or has distant outliers, we need sample sizes larger than $30$.

There is an extra pair of conditions to achieve a normal sampling distribution for a **proportion**, known as the **success/failure criteria**: 

<br>
<div class='emphasis'>
If the **population proportion** is $p$, and the sample size is $n$, we can expect a normal sampling distribution of the proportion if  

$$n \times p \ge 10$$ and
$$n \times (1-p) \ge 10$$

The first of these is just the expected number of 'successes', and the latter, the expected number of 'failures', hence the name. 
</div>
<br>

This means that it's easier to achieve a normal sampling distribution of a proportion if $p$ is around $0.5$. Conversely, $p$ values close to $0$ or $1$ will require larger samples to achieve normality.

<br>
<blockquote class='task'>
**Task - 2 mins**<br><br>
Roughly what size of sample do we need to achieve a normal sampling distribution for a proportion $p=0.01$ (i.e. one in a hundred)?
<details>
<summary>**Solution**</summary>
We need $0.01 \times n \ge 10$ and $0.99 \times n \ge 10$. Here, the 'limiting' condition to satisfy will be the first: $0.01 \times n \ge 10$. We can rewrite this as $n \ge \frac{10}{0.01}$, i.e. $n \ge 1000$.
</details>
</blockquote>
<br>

<hr>

# Standard error = standard deviation of the sampling distribution

The **width** of the sampling distribution is also really important! 

* If we have a **wide** sampling distribution, this directly relates to a **high degree of uncertainty** in a statistic. 
* Conversely, a **narrow** sampling distribution leads to a **low degree of uncertainty** in a statistic.

As you saw earlier this week, we often use **standard deviation** as a measure of the width of a distribution, so that's what we use to measure the width of a sampling distribution.

<br>
<center>
The standard deviation of a sampling distribution is given a special name: the **standard error**.
</center>
<br>

Let's get the standard errors for the three sampling distributions we have so far:

```{r}
std_errs <- rep_sample_200 %>%
  summarise(
    se_mean_monthly_charges = sd(mean_monthly_charges),
    se_mean_tenure = sd(mean_tenure),
    se_prop_churn = sd(prop_churn)
  )
std_errs
```

<br>
<details>
<summary>**Equations for standard errors from the central limit theorem**</summary>

The central limit theorem tells us **more** than that the sampling distributions are normal. If you work through the maths (which we won't do here), it also gives estimates for the standard error:  

| Sampling distribution | Standard error |
| --- | --- |
| Mean $\bar{x}$ | $\sigma_{\bar{x}} = \sqrt{\frac{N-n}{N-1}} \times \frac{\sigma}{\sqrt{n}}$ |
| Proportion $\bar{p}$ | $\sigma_{\bar{p}} = \sqrt{\frac{N-n}{N-1}} \times \sqrt{\frac{p \times (1-p)}{n}}$ |
  
In the formulae above, $\sigma$ and $p$ are **population parameters**, $N$ is the size of the population, and $n$ is the sample size. We'll see later what to do when we don't have access to population parameters. In fact, this will actually be the typical situation because, again, if we knew the population distribution ahead of time, there would be no need to do any statistics, we would just look at the population data we had! 

Factor $\sqrt{\frac{N-n}{N-1}}$ is called the **finite population correction**. It becomes significant in general if your sample is a large proportion of your population, typically $\frac{n}{N} \ge 0.05$. For smaller samples, the correction goes to $1$.

<br>
<center>
**Keep in your mind that these formulae are built on the understanding that sampling distributions are nearly normal.** i.e. these formulae will 'work' well if the central limit theorem is obeyed. 
</center>
<br>

Let's compare the standard errors we calculated earlier directly from the sampling distribution with those we get from the formulae from the central limit theorem. First, here are some helper functions we'll need:

```{r}
# SLACK THIS OUT
# first, write a helper function to compute finite population correction
finite_correction <- function(n, N){
  return(sqrt((N-n)/(N-1)))
}

standard_error_mean <- function(n, N, popn_stdev){
  se_mean <- finite_correction(n, N) * popn_stdev / sqrt(n)
  return(se_mean)
}

standard_error_proportion <- function(n, N, popn_prop){
  se_proportion <- finite_correction(n, N) * sqrt(popn_prop * (1 - popn_prop) / n)
  return(se_proportion)
}
```

Now apply our homebrew `standard_error_mean()` and `standard_error_proportion()` functions: 

```{r}
# sample size
n <- 200
# population size
N <- nrow(telco)
# need standard deviation from the population
sd_monthly_charges <- sd(telco$monthly_charges)

stderr_mean_monthly_charges <- standard_error_mean(n = n, N = N, popn_stdev =  sd_monthly_charges)
stderr_mean_monthly_charges
# compare with earlier value
std_errs$se_mean_monthly_charges
```

```{r}
sd_tenure <- sd(telco$tenure)
stderr_mean_tenure <- standard_error_mean(n = n, N = N, popn_stdev =  sd_tenure)
stderr_mean_tenure
# compare with earlier value
std_errs$se_mean_tenure
```


```{r}
popn_churn_prop <- mean(telco$churn == "Yes")
stderr_prop_churn <- standard_error_proportion(n = n, N = N, popn_prop = popn_churn_prop)
stderr_prop_churn
# compare with earlier value
std_errs$se_prop_churn
```

All of these values are pretty close! This should hopefully increase your confidence that the formulae for the standard errors from the central limit theorem are correct. 

Going forward, however, we won't be using these formulae, as we will perform **bootstrapping** to simulate drawing repeated samples. This is a more straightforward and powerful method, and, importantly, doesn't rely on the sampling distribution being close to normal. What we've shown you here is the 'older' statistics theory used when computer power was more limited and distributions couldn't be resampled so easily. Saying this, though, the traditional concepts are widespread and you may well come across them in statistical reports.
</details>
<br>

# Putting it all together: sampling distributions, standard errors and probabilities

The standard error tells us how broad the sampling distribution will be, and the central limit theorem tells us that the sampling distribution will be normal for big enough samples. 

If we put these together, we are in a position to start to estimate the probabilities of obtaining statistics in a given range around the population parameter.

Let's try to answer this question:

<br>
<center>
Imagine we repeatedly draw lots of $200$-observation samples from the `telco` population. Given what we now know about sampling `mean(monthly_charges)`, what proportion of these samples will have a `mean(monthly_charges)` in the range from $60$ to $70$ Euros?
</center>
<br>

For 'proportion' we can read 'probability', and the sampling distribution of `mean(monthly_charges)` directly answers this question! We know that it:

* will be normal (the sample size is well above $30$)
* will be centred close to `mean(monthly_charges)`
* will have a width equal to the standard error in `mean(monthly_charges)` for samples of size $200$.

Think back to earlier in the week when we shaded areas under probability density plots to get probabilities. We can do the same thing here to answer the question above!

We'll use the `shadeDist()` function in the `fastGraph` package to shade a normal plot (it also directly gives us the probability):

```{r, message=FALSE}
# fastGraph gives us the shadeDist() function
library(fastGraph)
```

```{r}
# we need the mean(mean_monthly_charges) to center the curve
# and the sample_size = 200 standard error in the mean to give the curve width
# shadeDist can shade regions on a prob dist and report probability
# parm1 is mean
# parm2 is sd
shadeDist(
  xshade = c(60, 70), 
  lower.tail = FALSE, 
  ddist = "dnorm", 
  parm1 = mean(rep_sample_200$mean_monthly_charges), 
  parm2 = std_errs$se_mean_monthly_charges, 
  xlab = "mean_monthly_charges"
)
```

How do we interpret this? As follows: $98\%$ of the $200$-observation samples of `monthly_charges` we draw from `telco` will have a mean `monthly_charges` in the range from $60$ to $70$ Euros.

Another way we could do this is to take the `mean_monthly_charges` sampling distribution we calculated above, filter it according to the criteria in the question (`mean_monthly_charges >= 60` and `mean_monthly_charges <= 70`), and then calculate the probability as: 

$$\textrm{prob} = \frac{\textrm{no. of values in filtered distribution}}{\textrm{no. of values in original distribution}}$$

```{r}
rep_sample_200 %>%
  filter(mean_monthly_charges >= 60, mean_monthly_charges <= 70) %>%
  summarise(prob = n() / nrow(rep_sample_200))
```

So the probabilities (proportions) calculated both ways are very similar! But which of these methods is better? The second is preferable, as it **doesn't make any assumption that the sampling distribution is normal**. We'll use resampling methods like this throughout the rest of the week. 

<br>
<blockquote class='task'>
**Task - 10 mins**

Try creating either a shaded normal plot or use the filtering method to answer this question:   
<br>
<center>
What proportion of $200$-observation samples of `tenure` will have a `mean(tenure)` in the range $30$ to $35$ months?
</center>

<br>
<details>
<summary>**Solution**</summary>
```{r}
shadeDist(
  xshade = c(30, 35), 
  lower.tail = FALSE, 
  ddist = "dnorm", 
  parm1 = mean(rep_sample_200$mean_tenure), 
  parm2 = std_errs$se_mean_tenure, 
  xlab = "mean_tenure"
)
```
```{r}
prob <- rep_sample_200 %>%
  filter(mean_tenure >= 30, mean_tenure <= 35) %>%
  summarise(prob = n() / nrow(rep_sample_200))

prob
```

So, $`r round(prob$prob * 100)`\%$ of $200$-observation samples of `tenure` will have a `mean(tenure)` in the range $30$ to $35$ months.
</details>
<br>

<hr>

# Standard errors in statistical tests

The standard error plays a key role in statistics because most test statistics take the form

<br>
$$\textrm{test statistic} = \frac{\textrm{observed effect size}}{\textrm{standard error}}$$
<br>

The standard error models 'uncertainty', 'noise' or 'natural variation'. We are basically asking **is the observed effect size _large enough_ that it is unlikely to have occurred by chance?**. To answer this, a test compares the test statistic to a critical value that depends upon how confident we want to be in our assertion

<br>
$$\textrm{test statistic} = \frac{\textrm{observed effect size}}{\textrm{standard error}} \ge \textrm{critical value}$$
<br>

<hr>

# Recap

* What is a sampling distribution?
<details>
<summary>**Answer**</summary>
The distribution of an observation we get by **repeatedly sampling** a population and calculating that observation for each resample.
</details>

<br>

* Why are sampling distributions important?
<details>
<summary>**Answer**</summary>
The width of the sampling distribution tells us how much certainty we can have in a calculated statistic. Wide sampling distribution means we only know the statistic with low precision. 
</details>

<br>

* What is the standard error?
<details>
<summary>**Answer**</summary>
The standard error is the `sd()` of the sampling distribution.
</details>

<br>

* What does the central limit theorem tell us? Why is it important?
<details>
<summary>**Answer**</summary>

  * That the sampling distribution of a statistic will be normal for a large enough number of large enough resamples of a population.
  * It also provides equations for the standard errors of the mean and a proportion (see dropdown above).
  * It's important because, often, we will just have a **single sample** drawn from a population. We won't be in a position to draw lots of samples and build up the sampling distribution of the statistic we are interested in. The central limit theorem tells us that this unknown sampling distribution would be normal (if sample size is over $30$) and also tells us the standard error, i.e. the width of the distribution.

</details>




