---
title: "Manual model building - EXPLANATORY."
output: html_notebook
---
```{r}
library(car)
library(tidyverse)
library(modelr)
library(GGally)
```
```{r}
head(Prestige)
```
```{r}
summary(Prestige)
```
```{r}
prestige_trim <- Prestige %>%
  drop_na() %>%
  select(-census)

dim(prestige_trim)
```

Our aim is to build an explanatory model for prestige of an occupation - we want to be able to explain which variables are important in establishing the presige.

```{r}
prestige_trim %>%
  ggpairs(aes(colour = type, alpha = 0.5))
```

## First predictor

```{r}
mod1a <- lm(prestige~education, data = prestige_trim)
summary(mod1a)
```
```{r}
par(mfrow = c(2,2))
plot(mod1a)
```
```{r}
mod1b <- lm(prestige ~ type, data = prestige_trim)
summary(mod1b)
par(mfrow = c(2,2))
plot(mod1b)
```

Winning model: prestige ~ education. RSE = 8.758, r-squared = 0.75

## Second predictor.

```{r}
prestige_remaning_resid <- prestige_trim %>%
  add_residuals(mod1a) %>%
  select(-c("prestige", "education"))
```
```{r}
prestige_remaning_resid %>%
  ggpairs(aes(colour = type, alpha = 0.5))
```
```{r}
mod2a <- lm(prestige ~ education + income, data = prestige_trim)
summary(mod2a)
```
```{r}
mod2b <- lm(prestige ~ education + type, data = prestige_trim)
summary(mod2b)
```
```{r}
par(mfrow = c(2,2))
plot(mod2b)
```

ANOVA - analysis of variance

Did inclyding type (with all its levels) improve the model over mod1a

```{r}
#mod1a is nested inside mod2b

anova(mod1a, mod2b)
```

Winning model: prestige ~ education + income, RSE = 7.45, r2 = 0.814

# Third predictor

```{r}
prestige_remaning_resid <- prestige_trim %>%
  add_residuals(mod2a) %>%
  select(-c("prestige", "education", "income"))

prestige_remaning_resid %>%
  ggpairs(aes(colour = type, alpha = 0.5))
```

```{r}
mod3a <- lm(prestige ~ education + income + women, data = prestige_trim)
summary(mod3a)
```
```{r}
mod3b <- lm(prestige ~ education + income + type, data = prestige_trim)
summary(mod3b)
```

```{r}
par(mfrow = c(2,2))
plot(mod3b)
```


```{r}
anova(mod3b, mod2a)
```

Winning model mod3b: prestige ~ education + income + type, RSE = 7.095, r2 = 0.8349

# Adding interactions

possible (hierarchical) interactions

* education: income
* education: type
* income: type

non- hierarchical (wont work):

women: type

```{r}
prestige_resid <- prestige_trim %>%
  add_residuals(mod3b) %>%
  select(-prestige)
```

Coplot to visualise interactions between continuous variables

```{r}
coplot(resid ~ income | education, data = prestige_resid, columns = 6)
```

```{r}
mod4a <- lm(prestige ~ education + income + type + education:income, data = prestige_trim)
summary(mod4a)
```
```{r}
mod4b <- lm(prestige ~ education + income + type + education:type, data = prestige_trim)
summary(mod4b)
```
```{r}
mod4c <- lm(prestige ~ education + income + type + income: type, data = prestige_trim)
summary(mod4c)
```

```{r}
options(scipen = 999)
anova(mod4c, mod3b)
```

Which factor is the most important?

```{r}
library(relaimpo)
```
```{r}
calc.relimp(mod4c, type = "lmg", rela = TRUE)
```

# Variable reduction and dimensionality reduction.

(PCA - Principle Component Adjustment)

PCA main goal is to find what minimizes the error and maximizes the variance.
PCA only good for numerical data, data needs to be standartised.

```{r}
mtcars
```
```{r}
#library(tidyverse)
cars_numeric <- mtcars %>%
  dplyr::select(-c(vs,am))

dim(cars_numeric)
```
```{r}
cars_pca <- prcomp(cars_numeric,
                   center = TRUE,
                   scale. = TRUE)
cars_pca #difficult to understand, better to use summary()
```
```{r}
summary(cars_pca)
```

```{r}
library(ggbiplot)
ggbiplot(cars_pca, 
         obs.scale = 1,
         var.scale = 1)
```

















